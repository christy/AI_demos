{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cz8s-sPDIIIr"
   },
   "outputs": [],
   "source": [
    "# !pip install datasets tiktoken openai wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AlfkQQwHIA9i"
   },
   "source": [
    "# Fine Tuning using OpenAI GPT-4o\n",
    "\n",
    "See the pricing page:\n",
    "https://openai.com/api/pricing/\n",
    "\n",
    "**Fine-tuning for GPT-4o and GPT-4o mini is free up to a daily token limit through October 31, 2024. \n",
    "\n",
    "`gpt-4o-2024-08-06`\n",
    "For GPT-4o, each qualifying org gets up to 1M complimentary training tokens daily and any overage will be charged at the normal rate of $25.00/1M tokens. \n",
    "\n",
    "`gpt-4o-mini-2024-07-18`\n",
    "For GPT-4o mini, each qualifying org gets up to 2M complimentary training tokens daily and any overage will be charged at the normal rate of $3.00/1M tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "qu6Ufq_5H8fu"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "# openai.api_key = ''\n",
    "openai.api_key=os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Set the model name\n",
    "model_name = \"gpt-4o-mini-2024-07-18\"\n",
    "# model_name = \"gpt-4o-2024-08-06\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "884i8XBUIiwy"
   },
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kwcVDj5-LCrY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['conversations', 'source', 'score'],\n",
      "        num_rows: 100000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "# Maxime Labonne's ai knowledge dataset.\n",
    "# https://huggingface.co/datasets/mlabonne/FineTome-100k\n",
    "ds = load_dataset(\"mlabonne/FineTome-100k\")\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['conversations', 'source', 'score'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['conversations', 'source', 'score'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['conversations', 'source', 'score'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "import json\n",
    "\n",
    "TRAIN_SIZE = 100\n",
    "VALID_SIZE = 100\n",
    "TEST_SIZE = 100\n",
    "\n",
    "# Shuffle data\n",
    "ds = ds.shuffle(seed=42)\n",
    "\n",
    "# Split off a small 'test' dataset.\n",
    "ds_split_test = ds['train'].train_test_split(test_size=TEST_SIZE)\n",
    "\n",
    "# Split off a small 'valid' dataset.\n",
    "ds_split_valid = ds_split_test['train'].train_test_split(test_size=VALID_SIZE)\n",
    "\n",
    "# Split off a small 'train' dataset from the remaining train dataset.\n",
    "ds_split_train = ds_split_valid['train'].train_test_split(test_size=TRAIN_SIZE)\n",
    "\n",
    "# Create a new DatasetDict to hold the train, valid, test sets\n",
    "ds = DatasetDict({\n",
    "    'test': ds_split_test['test'],\n",
    "    'valid': ds_split_valid['test'],\n",
    "    'train': ds_split_train['test'],\n",
    "})\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12d83de1301d4b8eac2197c657d43661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "993e6f86254f42d6a2fe42b29c0d8909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99338083bbf5400eb036621507b25086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "021449acd10e4d9aa807b111138decad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2955cb1ee879412f9b1added411920dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating valid split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8730f0edffb549079629a86612033372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['conversations', 'source', 'score'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['conversations', 'source', 'score'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['conversations', 'source', 'score'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Common patterns for Hugging Face Datasets\n",
    "# https://www.youtube.com/watch?app=desktop&v=blF9uxYcKHo\n",
    "from datasets import load_dataset, load_from_disk\n",
    "\n",
    "# # 1. ARROW datasets directly.\n",
    "# # Create a new dir and save Arrow format, typically in 3 folders: train, valid, test.\n",
    "# # Splits info stored in the file: new_dir/dataset_dict.json.\n",
    "# ds.save_to_disk('my-arrow-datasets')\n",
    "# # Read them back into memory anytime.\n",
    "# ds_saved = load_from_disk('my-arrow-datasets')\n",
    "# ds_saved\n",
    "\n",
    "# 2. datasets to/from JSON Lines files.\n",
    "# Loop through ds dict object, create new dir, save each split to a JSON Lines file.\n",
    "for split, dataset in ds.items():\n",
    "    dataset.to_json(f'data/fine_tome_{split}.json', orient='records', lines=True) \n",
    "data_files={'train': 'data/fine_tome_train.json', 'valid': 'data/fine_tome_valid.json', 'test': 'data/fine_tome_test.json'}\n",
    "json_datasets_saved = load_dataset('json', data_files=data_files)\n",
    "print(json_datasets_saved)\n",
    "\n",
    "# # 3. datasets to/from Parquet, more efficient for big data.\n",
    "# # Loop through ds dict object, create new dir, save each split to a .parquet file.\n",
    "# for split, dataset in ds.items():\n",
    "#     dataset.to_parquet(f'my-parquet-datasets/{split}.parquet') \n",
    "# data_files={'train': 'my-parquet-datasets/train.parquet', 'valid': 'my-parquet-datasets/valid.parquet', 'test': 'my-parquet-datasets/test.parquet'}\n",
    "# parquet_datasets_saved = load_dataset('parquet', data_files=data_files)\n",
    "# print(parquet_datasets_saved)\n",
    "\n",
    "# # 4. datasets to/from CSV files, less efficient for big data.\n",
    "# # Loop through ds dict object, create new dir, save each split to a CSV file.\n",
    "# for split, dataset in ds.items():\n",
    "#     dataset.to_csv(f'my-csv-datasets/{split}.csv', index=None)\n",
    "# data_files={'train': 'my-csv-datasets/train.csv', 'valid': 'my-csv-datasets/valid.csv', 'test': 'my-csv-datasets/test.csv'}\n",
    "# csv_datasets_saved = load_dataset('csv', data_files=data_files)\n",
    "# csv_datasets_saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Double-check row counts of the saved datasets.\n",
    "\n",
    "# # Compare the original data with the data read from the file\n",
    "# original_data = ds['train']\n",
    "# # Check datatypes.\n",
    "# print(type(original_data), type(json_datasets_saved['train']))\n",
    "# # Check number of rows.\n",
    "# print(len(original_data), len(json_datasets_saved['train']))\n",
    "# # Check if the data matches.\n",
    "# print(original_data == json_datasets_saved['train'])\n",
    "# print(original_data.to_dict() == json_datasets_saved['train'].to_dict())\n",
    "# # False, inspect 1 row.\n",
    "# print(original_data[10]['conversations'])\n",
    "# print(json_datasets_saved['train'][10]['conversations'])\n",
    "\n",
    "# # hmm, spot-check looks the same to me, try to find the differences?\n",
    "# import deepdiff\n",
    "# # Perform a detailed comparison\n",
    "# differences = deepdiff.DeepDiff(original_data, json_datasets_saved['train'], ignore_order=True)\n",
    "# print(\"Differences:\", differences)\n",
    "# # No differences found!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format data for Fine-tuning\n",
    "\n",
    "Use OpenAI Cookbook\n",
    "\n",
    "https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use `standardize_sharegpt` to convert ShareGPT style datasets into HuggingFace's generic format. This changes the dataset from looking like:\n",
    "\n",
    "```json\n",
    "{\"from\": \"system\", \"value\": \"You are an assistant\"}\n",
    "{\"from\": \"human\", \"value\": \"What is 2+2?\"}\n",
    "{\"from\": \"gpt\", \"value\": \"It's 4.\"}\n",
    "```\n",
    "to\n",
    "```json\n",
    "{\"messages\": [\n",
    "    {\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"},{\"role\": \"user\", \"content\": \"What's the capital of France?\"}, {\"role\": \"assistant\", \"content\": \"Paris, as if everyone doesn't know that already.\"}]}\n",
    "{\"messages\": [\n",
    "    {\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who wrote 'Romeo and Juliet'?\"}, {\"role\": \"assistant\", \"content\": \"Oh, just some guy named William Shakespeare. Ever heard of him?\"}]}\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"How far is the Moon from Earth?\"}, {\"role\": \"assistant\", \"content\": \"Around 384,400 kilometers. Give or take a few, like that really matters.\"}]}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert the dictionaries\n",
    "def convert_dicts(dict_list, system_message=\"Think before responding.\"):\n",
    "    \"\"\"Convert a list of HF conversations to list of GPT Multi-turn messages. \n",
    "    Each turn begins with 1 system message and can continue with many user, \n",
    "    assistant messages. Skip fine-tuning on all but last assistant messages \n",
    "    per turn. That is, set weight=0 on all but last assistant message per turn.\n",
    "    https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset\n",
    "\n",
    "    Args:\n",
    "        dict_list (_type_): HF conversation list of dicts\n",
    "        system_message (str, optional): Defaults to \"Think before responding\".\n",
    "\n",
    "    Returns:\n",
    "        _type_: OpenAI GPT Multi-turn messages list of dicts\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "    system_message_added = False\n",
    "    assistant_indices = []\n",
    "\n",
    "    for d in dict_list:\n",
    "        if \"from\" in d:\n",
    "            if d[\"from\"] == \"system\":\n",
    "                # Process the previous turn's assistant messages\n",
    "                if assistant_indices:\n",
    "                    messages[assistant_indices[-1]][\"weight\"] = 1\n",
    "                    assistant_indices = []\n",
    "                # Process the system message\n",
    "                messages.insert(0, {\"role\": \"system\", \"content\": d[\"value\"]})\n",
    "                system_message_added = True\n",
    "            elif d[\"from\"] == \"human\":\n",
    "                messages.append({\"role\": \"user\", \"content\": d[\"value\"]})\n",
    "            elif d[\"from\"] == \"gpt\":\n",
    "                messages.append({\"role\": \"assistant\", \"content\": d[\"value\"], \"weight\": 0})\n",
    "                assistant_indices.append(len(messages) - 1)\n",
    "            else:\n",
    "                messages.append({\"role\": \"user\", \"content\": d[\"value\"]})\n",
    "        else:\n",
    "            messages.append(d)  # Keep the original dictionary if 'from' key is missing\n",
    "    \n",
    "    # Process the last turn's assistant messages\n",
    "    if assistant_indices:\n",
    "        messages[assistant_indices[-1]][\"weight\"] = 1\n",
    "    \n",
    "    # Include the system message if none provided\n",
    "    if not system_message_added:\n",
    "        messages.insert(0, {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_message\n",
    "        })\n",
    "    \n",
    "    return messages\n",
    "\n",
    "def save_to_jsonl(conversations, file_path):\n",
    "  with open(file_path, 'w') as file:\n",
    "    for conversation in conversations:\n",
    "      json_line = json.dumps(conversation)\n",
    "      file.write(json_line + '\\n')\n",
    "\n",
    "def process_and_save(system_message, in_json_file_path, out_json_file_path):\n",
    "\n",
    "    # Load dataset from input json file.\n",
    "    test_jsonl = []\n",
    "    with open(in_json_file_path) as f:\n",
    "        test_jsonl = [ json.loads(line) for line in f]\n",
    "    # print(f\"input: {len(test_jsonl[0])}\")  # 3\n",
    "\n",
    "    gpt_format = []\n",
    "    for item in test_jsonl:\n",
    "        # print(item)\n",
    "        conversation = item['conversations']\n",
    "        conversation = convert_dicts(conversation, system_message)\n",
    "        formatted_conversation = {\"messages\": conversation}\n",
    "        gpt_format.append(formatted_conversation)\n",
    "    \n",
    "    print(f\"Number of conversations: {len(gpt_format)}\")\n",
    "    save_to_jsonl(gpt_format, out_json_file_path)\n",
    "\n",
    "# Input:\n",
    "# {'conversations': [{'from': 'human', 'value': \"In a gravity-free and balanced, the total pressure at the center remains $P=\\\\dfrac{F}{A}$.\"}], 'source': 'WebInstructSub_axolotl', 'score': 3.8947217464}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples HF: 100\n",
      "HF example:\n",
      "Num examples GPT: 100\n",
      "14th GPT example:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'system', 'content': 'Think before responding.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'Discuss the ways in which Latin American art has impacted and influenced the content, style, and techniques of Western art throughout history. Provide specific examples of Latin American artists and their works that have had a significant impact on the development of Western art movements and styles. Analyze the cultural, political, and social factors that have contributed to this influence and explore how contemporary Western art continues to be shaped by Latin American artistic traditions.'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'Latin American art has had a significant impact on the history of Western art throughout the centuries. From the vibrant colors and imagery of the pre-Columbian era to contemporary works by artists like Frida Kahlo and Gabriel Orozco, Latin American art continues to inspire and challenge Western artists.\\n\\nOne of the primary ways that Latin American art has influenced Western art is through its use of color and symbolism. For example, the bright, bold colors of Mexican art have had an enormous impact on abstraction and Pop art in the 20th century. In particular, the work of Mexican muralist Diego Rivera, known for his political murals, influenced the development of the muralist movement in the United States.\\n\\nSimilarly, the rich storytelling traditions of Latin American art have inspired Western artists to explore their own narratives and histories in their works. For instance, the Surrealist movement was deeply influenced by the work of Latin American artists like Kahlo, whose dreamlike and surreal paintings often contained deeply personal and politically charged narratives.\\n\\nThe cultural and social factors that have contributed to this influence are complex and multifaceted. One of the key factors is the deep history and diversity of Latin American cultures, which have inspired artists across genres and time periods. Additionally, the political and social upheavals of the 20th century in Latin America, including the Mexican Revolution and Cuban Revolution, have led to a vibrant and diverse artistic scene that has had a significant impact on Western art.\\n\\nEven today, Latin American art continues to shape contemporary Western art. Artists like Orozco continue to push boundaries and experiment with forms and techniques, inspiring a new generation of artists to explore new possibilities in their own work. Ultimately, the influence of Latin American art on Western art is a testament to the enduring power of art to transcend cultural boundaries and inspire creativity across the world.',\n",
       "   'weight': 0},\n",
       "  {'role': 'user',\n",
       "   'content': 'Thanks for providing such an insightful discussion on the influence of Latin American art on Western art movements and styles throughout history. It is quite interesting to see how deeply embedded Latin American art is within Western art. I would like to know more about the political and social factors that led to the diverse and vibrant artistic scenes in Latin America. Could you please add some more detail about the political and social upheavals in Latin America that have influenced art movements and styles? Additionally, could you provide more examples of contemporary Western artists who continue to be shaped by Latin American artistic traditions?'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'Certainly! The political and social upheavals in Latin America have had a significant impact on art movements and styles over the years. One such example is the Mexican muralist movement, which emerged in the wake of the Mexican Revolution (1910-1920). Artists like Diego Rivera, David Alfaro Siqueiros, and José Clemente Orozco played a key role in this movement, which aimed to use public art as a means of informing and educating the masses about Mexican history, culture, and social justice issues. Through their murals, the Mexican muralists sought to foster a sense of national identity and pride, while also highlighting Mexico’s struggles for social and political change.\\n\\nSimilarly, the Cuban Revolution (1953–1959) had a profound influence on Cuban art and culture, as artists sought to create a new, revolutionary aesthetic that reflected the aspirations of the Cuban people. One of the most notable examples of this is the work of Wifredo Lam, a Cuban artist with Chinese, African, and European ancestry. His fusion of influences from diverse cultures, along with his engagement with revolutionary politics, resulted in a unique artistic vision that continues to inspire artists today.\\n\\nContemporary Western artists who continue to be shaped by Latin American artistic traditions include Brazilian mixed-media artist Vik Muniz, Colombian sculptor Doris Salcedo, and Mexican photographer Graciela Iturbide. Muniz incorporates everyday materials like sugar, garbage, and chocolate into his works, exploring issues of identity, memory, and culture. Salcedo transforms everyday objects like chairs and kitchen tables into powerful sculptures that explore themes of loss, mourning, and violence. And Iturbide’s photographs document the rich cultural heritage and natural beauty of Mexico, while also challenging stereotypes and highlighting social injustice.\\n\\nOverall, the influence of Latin American art on Western art is a testament to the enduring power of creative expression to transcend cultural and political boundaries, and to inspire new generations of artists to push boundaries and explore new possibilities.',\n",
       "   'weight': 1}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST THE CONVERSION FUNCTIONS FROM HF TO GPT FORMATS.\n",
    "\n",
    "temp = json_datasets_saved['test']\n",
    "print(\"Num examples HF:\", len(temp))\n",
    "print(\"HF example:\")\n",
    "TEST_ROW = 13\n",
    "temp[TEST_ROW]\n",
    "\n",
    "# Convert the list of dictionaries\n",
    "gpt_format = []\n",
    "system_message = \"\"\"Think before responding.\"\"\"\n",
    "\n",
    "for item in temp:\n",
    "    conversation = item['conversations']\n",
    "    conversation = convert_dicts(conversation, system_message)\n",
    "    formatted_conversation = {\"messages\": conversation}\n",
    "    gpt_format.append(formatted_conversation)\n",
    "    \n",
    "# gpt_format\n",
    "print(\"Num examples GPT:\", len(gpt_format))\n",
    "print(\"14th GPT example:\")\n",
    "gpt_format[TEST_ROW]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing and saving train data...\n",
      "Number of conversations: 100\n",
      "Processing and saving valid data...\n",
      "Number of conversations: 100\n",
      "Processing and saving test data...\n",
      "Number of conversations: 100\n"
     ]
    }
   ],
   "source": [
    "system_message = \"\"\"Think before responding.\"\"\"\n",
    "\n",
    "# Process and save the train dataset\n",
    "in_json_file_path = \"data/fine_tome_train.json\"\n",
    "train_data_filename = \"data/fine_tome_train_gpt.jsonl\"\n",
    "print(\"Processing and saving train data...\")\n",
    "process_and_save(\n",
    "    system_message, \n",
    "    in_json_file_path, train_data_filename)\n",
    "\n",
    "# Process and save the valid dataset\n",
    "in_json_file_path = \"data/fine_tome_valid.json\"\n",
    "valid_data_filename = \"data/fine_tome_valid_gpt.jsonl\"\n",
    "print(\"Processing and saving valid data...\")\n",
    "process_and_save(\n",
    "    system_message, \n",
    "    in_json_file_path, valid_data_filename)\n",
    "\n",
    "# Process and save the test dataset\n",
    "in_json_file_path = \"data/fine_tome_test.json\"\n",
    "test_data_filename = \"data/fine_tome_test_gpt.jsonl\"\n",
    "print(\"Processing and saving test data...\")\n",
    "process_and_save(\n",
    "    system_message, \n",
    "    in_json_file_path, test_data_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Data Format Errors\n",
    "\n",
    "Use OpenAI Cookbook sample code.\n",
    "\n",
    "https://cookbook.openai.com/examples/chat_finetuning_data_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tiktoken # for token counting\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'system', 'content': 'Think before responding.'},\n",
       "  {'role': 'user',\n",
       "   'content': 'Solve the following problem step-by-step:\\nGiven the context and corresponding question, choose the correct answer from the options.\\n\\nContext: \\nPeople often pronounce a word differently when asked to read written material aloud than when speaking spontaneously. These differences may cause problems for those who develop computers that recognize speech. Usually the developers \"train\" the computers by using samples of written material read by the people who will be using the computer.\\n\\nQuestion: \\nThe observations above provide most evidence for the conclusion that\\n\\nOptions: \\nA. computers may be less reliable in decoding spontaneous speech than in decoding samples that have been read aloud\\nB. it will be impossible to develop computers that decode spontaneous speech\\nC. computers are now able to interpret oral speech without error\\nD. a \"trained\" computer never correctly decodes the spontaneous speech of a person whose voice sample was used to train it\\n\\n'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'Step 1: The context states that people often pronounce a word differently when asked to read written material aloud compared to when speaking spontaneously.\\nStep 2: These differences may cause problems for developers who are trying to create computers that recognize speech.\\nStep 3: Developers typically \"train\" the computers by using samples of written material read aloud by the people who will be using the computer.\\nStep 4: Option A: The context supports the conclusion that computers may be less reliable in decoding spontaneous speech compared to samples that have been read aloud. This is because people pronounce words differently in these two scenarios, which can cause confusion for the computer\\'s speech recognition system.\\nStep 5: Option B: The context does not provide evidence to support the conclusion that it will be impossible to develop computers that decode spontaneous speech.\\nStep 6: Option C: The context does not provide evidence to support the conclusion that computers are now able to interpret oral speech without error.\\nStep 7: Option D: The context does not provide evidence to support the conclusion that a \"trained\" computer never correctly decodes spontaneous speech.\\nStep 8: Based on the evidence provided, the conclusion most strongly supported by the statements is that computers may be less reliable in decoding spontaneous speech than in decoding samples that have been read aloud. So choose A.\\nAnswer:\\nA',\n",
       "   'weight': 1}]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the JSONL file\n",
    "\n",
    "# Check: load dataset from json file.\n",
    "file_path = test_data_filename\n",
    "temp = []\n",
    "with open(file_path) as f:\n",
    "  temp = [ json.loads(line) for line in f]\n",
    "print(f\"test: {len(temp)}\")  # 100\n",
    "\n",
    "temp[5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for data formatting errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors found\n"
     ]
    }
   ],
   "source": [
    "# Format error checks\n",
    "format_errors = defaultdict(int)\n",
    "\n",
    "for ex in temp:\n",
    "    if not isinstance(ex, dict):\n",
    "        format_errors[\"data_type\"] += 1\n",
    "        continue\n",
    "        \n",
    "    messages = ex.get(\"messages\", None)\n",
    "    if not messages:\n",
    "        format_errors[\"missing_messages_list\"] += 1\n",
    "        continue\n",
    "        \n",
    "    for message in messages:\n",
    "        if \"role\" not in message or \"content\" not in message:\n",
    "            format_errors[\"message_missing_key\"] += 1\n",
    "        \n",
    "        if any(k not in (\"role\", \"content\", \"name\", \"function_call\", \"weight\") for k in message):\n",
    "            format_errors[\"message_unrecognized_key\"] += 1\n",
    "        \n",
    "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
    "            format_errors[\"unrecognized_role\"] += 1\n",
    "            \n",
    "        content = message.get(\"content\", None)\n",
    "        function_call = message.get(\"function_call\", None)\n",
    "        \n",
    "        if (not content and not function_call) or not isinstance(content, str):\n",
    "            format_errors[\"missing_content\"] += 1\n",
    "    \n",
    "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "        format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "if format_errors:\n",
    "    print(\"Found errors:\")\n",
    "    for k, v in format_errors.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "else:\n",
    "    print(\"No errors found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate Num Tokens, to estimate costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "2k_7ssdfRnDF"
   },
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# helper functions to token counting, not exact!\n",
    "# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            if isinstance(value, str):  # Ensure the value is a string\n",
    "                num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "def print_distribution(values, name):\n",
    "    print(f\"\\n#### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples missing system message: 0\n",
      "Num examples missing user message: 0\n",
      "\n",
      "#### Distribution of num_messages_per_example:\n",
      "min / max: 3, 25\n",
      "mean / median: 3.88, 3.0\n",
      "p5 / p95: 3.0, 5.0\n",
      "\n",
      "#### Distribution of num_total_tokens_per_example:\n",
      "min / max: 114, 4167\n",
      "mean / median: 620.52, 439.0\n",
      "p5 / p95: 230.9, 1102.3000000000002\n",
      "\n",
      "#### Distribution of num_assistant_tokens_per_example:\n",
      "min / max: 6, 3829\n",
      "mean / median: 432.29, 306.5\n",
      "p5 / p95: 150.4, 768.9000000000004\n",
      "\n",
      "0 examples may be over the 16,385 token limit, they will be truncated during fine-tuning\n"
     ]
    }
   ],
   "source": [
    "# Warnings and tokens counts\n",
    "n_missing_system = 0\n",
    "n_missing_user = 0\n",
    "n_messages = []\n",
    "convo_lens = []\n",
    "assistant_message_lens = []\n",
    "\n",
    "for ex in temp:\n",
    "    messages = ex[\"messages\"]\n",
    "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
    "        n_missing_system += 1\n",
    "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
    "        n_missing_user += 1\n",
    "    n_messages.append(len(messages))\n",
    "    convo_lens.append(num_tokens_from_messages(messages))\n",
    "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
    "    \n",
    "print(\"Num examples missing system message:\", n_missing_system)\n",
    "print(\"Num examples missing user message:\", n_missing_user)\n",
    "print_distribution(n_messages, \"num_messages_per_example\")\n",
    "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
    "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
    "n_too_long = sum(l > 16385 for l in convo_lens)\n",
    "print(f\"\\n{n_too_long} examples may be over the 16,385 token limit, they will be truncated during fine-tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has ~62052 tokens that will be charged for during training\n",
      "By default, you'll train for 3 epochs on this dataset\n",
      "By default, you'll be charged for ~186156 tokens\n"
     ]
    }
   ],
   "source": [
    "# Pricing and default n_epochs estimate\n",
    "MAX_TOKENS_PER_EXAMPLE = 16385\n",
    "\n",
    "TARGET_EPOCHS = 3\n",
    "MIN_TARGET_EXAMPLES = 100\n",
    "MAX_TARGET_EXAMPLES = 25000\n",
    "MIN_DEFAULT_EPOCHS = 1\n",
    "MAX_DEFAULT_EPOCHS = 25\n",
    "\n",
    "n_epochs = TARGET_EPOCHS\n",
    "n_train_examples = len(dataset)\n",
    "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
    "    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
    "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
    "    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
    "\n",
    "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
    "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
    "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
    "total_billing_tokens = n_epochs * n_billing_tokens_in_dataset\n",
    "print(f\"By default, you'll be charged for ~{total_billing_tokens} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated cost is $0.33508079999999996\n"
     ]
    }
   ],
   "source": [
    "# Estimated training cost\n",
    "# https://openai.com/api/pricing/\n",
    "\n",
    "PER_TOKEN_COST = 0.0000003\n",
    "NUM_EPOCHS = 3\n",
    "NUM_DATASETS = 2\n",
    "\n",
    "print(f\"Estimated cost is ${total_billing_tokens * PER_TOKEN_COST * NUM_EPOCHS * NUM_DATASETS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "HXG7iGMhvsRx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'messages': [{'role': 'system', 'content': 'Think before responding.'},\n",
       "   {'role': 'user',\n",
       "    'content': 'A line segment is bisected by the line represented by the equation \\\\(2y + x = 7\\\\). If one endpoint of the line segment is at \\\\((5, 3)\\\\), determine the coordinates of the other endpoint.'},\n",
       "   {'role': 'assistant',\n",
       "    'content': \"The bisector's equation can be found by considering that it is perpendicular to the given line \\\\(L\\\\): \\\\(2y + x = 7\\\\), which has a gradient \\\\(m_L = -\\\\frac{1}{2}\\\\). The gradient of the bisector \\\\(B\\\\), \\\\(m_B\\\\), is the negative reciprocal of \\\\(m_L\\\\), so \\\\(m_B = 2\\\\).\\n\\nGiven a point \\\\((x_1, y_1)\\\\) on the bisector, we can express its equation as:\\n\\\\[y - y_1 = m_B (x - x_1)\\\\]\\n\\nUsing the point \\\\((5, 3)\\\\), the equation of the bisector \\\\(B\\\\) is:\\n\\\\[y - 3 = 2(x - 5)\\\\]\\n\\\\[y - 3 = 2x - 10\\\\]\\n\\\\[y = 2x - 7\\\\]\\n\\nThe intersection point \\\\(M\\\\) of \\\\(B\\\\) and \\\\(L\\\\) can be found by solving the system of equations:\\n\\\\[2y + x = 7\\\\]\\n\\\\[y = 2x - 7\\\\]\\n\\nSubstituting \\\\(y\\\\) from the second equation into the first:\\n\\\\[2(2x - 7) + x = 7\\\\]\\n\\\\[4x - 14 + x = 7\\\\]\\n\\\\[5x = 21\\\\]\\n\\\\[x = \\\\frac{21}{5}\\\\]\\n\\nThen, \\\\(y = 2 \\\\cdot \\\\frac{21}{5} - 7\\\\)\\n\\\\[y = \\\\frac{7}{5}\\\\]\\n\\nSo, point \\\\(M\\\\) is at \\\\(\\\\left(\\\\frac{21}{5}, \\\\frac{7}{5}\\\\right)\\\\).\\n\\nSince the line segment is bisected, the distance between \\\\(M\\\\) and the given endpoint \\\\((5, 3)\\\\) is equal to the distance between \\\\(M\\\\) and the other endpoint \\\\(Q\\\\). We can find \\\\(Q\\\\) by using vector equality:\\n\\\\[\\\\overrightarrow{PM} = \\\\overrightarrow{MQ}\\\\]\\n\\nThe vector \\\\(\\\\overrightarrow{PM}\\\\) is:\\n\\\\[\\\\left(\\\\frac{21}{5} - 5, \\\\frac{7}{5} - 3\\\\right) = \\\\left(-\\\\frac{4}{5}, -\\\\frac{8}{5}\\\\right)\\\\]\\n\\nHence, the vector \\\\(\\\\overrightarrow{MQ}\\\\) is the same:\\n\\\\[Q = M + \\\\left(-\\\\frac{4}{5}, -\\\\frac{8}{5}\\\\right)\\\\]\\n\\\\[Q = \\\\left(\\\\frac{21}{5} - \\\\frac{4}{5}, \\\\frac{7}{5} - \\\\frac{8}{5}\\\\right)\\\\]\\n\\\\[Q = \\\\left(\\\\frac{17}{5}, -\\\\frac{1}{5}\\\\right)\\\\]\\n\\nTherefore, the coordinates of the other endpoint are \\\\(\\\\left(\\\\frac{17}{5}, -\\\\frac{1}{5}\\\\right)\\\\).\",\n",
       "    'weight': 1}]}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pyjmBEX6xkic"
   },
   "source": [
    "**Training Data:**\n",
    "\n",
    "Definition:<br>\n",
    "  \n",
    "\n",
    "*   dataset used to train or update the model's parameters\n",
    "*   It is the input data that the model learns from.\n",
    "* During the training process, the model adjusts its internal parameters based on the patterns and features present in the training data.\n",
    "* Size is large as the model needs sufficient examples to learn meaningful patterns.\n",
    "\n",
    "\n",
    "**Validation Data:**\n",
    "\n",
    "* Dataset that is not used during the training phase.\n",
    "* Instead, it serves as a measure of the model's performance during training.\n",
    "* The validation set helps you monitor the model's generalization to new, unseen data and detect potential issues such as overfitting or underfitting.\n",
    "* unbiased evaluation of the model's performance on data it hasn't seen before.\n",
    "\n",
    "* Size is typically smaller than the training set but large enough to provide a reliable assessment of the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQF-NYtbwxCl"
   },
   "source": [
    "### Upload training/validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LXGLzX9e10ol"
   },
   "source": [
    "##### for openai ver 1.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "od5m-3Cp1n7p"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "# Set the model name\n",
    "model_name = \"gpt-4o-mini-2024-07-18\"\n",
    "# model_name = \"gpt-4o-2024-08-06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "odZa4e9stNtH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/fine_tome_train_gpt.jsonl\n",
      "data/fine_tome_valid_gpt.jsonl\n",
      "data/fine_tome_test_gpt.jsonl\n"
     ]
    }
   ],
   "source": [
    "print(train_data_filename)\n",
    "print(valid_data_filename)\n",
    "print(test_data_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "j2me1B5ZtNv-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-H0LeAG22X3404CTIHkuPE4EM', bytes=265449, created_at=1730069170, filename='fine_tome_train_gpt.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n",
      "file-H0LeAG22X3404CTIHkuPE4EM\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Upload the train data to OpenAI\n",
    "training_response = client.files.create(\n",
    "    file=Path(train_data_filename),\n",
    "    purpose=\"fine-tune\"\n",
    ")\n",
    "print(training_response)\n",
    "training_file_id = training_response.id\n",
    "print(training_file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Y0_rouGkF3ez"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-ReZ2mMJJYp67b2E7wMvFPqDO', bytes=241215, created_at=1730069172, filename='fine_tome_valid_gpt.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n",
      "file-ReZ2mMJJYp67b2E7wMvFPqDO\n"
     ]
    }
   ],
   "source": [
    "# Upload the valid data to OpenAI\n",
    "validation_response = client.files.create(\n",
    "    file=Path(valid_data_filename),\n",
    "    purpose=\"fine-tune\"\n",
    ")\n",
    "print(validation_response)\n",
    "validation_file_id = validation_response.id\n",
    "print(validation_file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d67aKQz_w0pl"
   },
   "source": [
    "### Start a fine-tuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-4o-mini-2024-07-18'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check your base model.\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data num samples: 100\n",
      "Batch size: 5\n"
     ]
    }
   ],
   "source": [
    "# Best practices: https://beta.openai.com/docs/guides/best-practices\n",
    "# Set batch size to approx 1/20th of the dataset size, for smoother learning curves.\n",
    "print(f\"Train data num samples: {TRAIN_SIZE}\")  \n",
    "batch_size = TRAIN_SIZE // 20\n",
    "print(f\"Batch size: {batch_size}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "i3MTc3MoJqY6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-dNsMjoTKcaJFJndhzPBsQgwh', created_at=1730071087, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier='auto'), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-0TvGxvi7iOVWbyYmOwLasUrl', result_files=[], seed=356598581, status='validating_files', trained_tokens=None, training_file='file-H0LeAG22X3404CTIHkuPE4EM', validation_file='file-ReZ2mMJJYp67b2E7wMvFPqDO', estimated_finish=None, integrations=[FineTuningJobWandbIntegrationObject(type='wandb', wandb=FineTuningJobWandbIntegration(project='my-wandb-project', entity=None, name=None, tags=None, run_id='ftjob-dNsMjoTKcaJFJndhzPBsQgwh'))], user_provided_suffix='finetome_try3')\n",
      "ftjob-dNsMjoTKcaJFJndhzPBsQgwh\n"
     ]
    }
   ],
   "source": [
    "# https://platform.openai.com/docs/api-reference/fine-tuning/create\n",
    "response = client.fine_tuning.jobs.create(\n",
    "    model = model_name,\n",
    "    training_file = training_file_id,\n",
    "    validation_file = validation_file_id,\n",
    "    suffix=\"finetome_try3\",\n",
    "    hyperparameters = {\n",
    "        \"n_epochs\": 3,  # overtrain since checkpointing is supported\n",
    "        \"batch_size\": 1, #batch_size, # 5, default is 1\n",
    "        # \"learning_rate_multiplier\": 1.8, # default 1.8\n",
    "    },\n",
    "    integrations = [{\n",
    "        \"type\": \"wandb\",\n",
    "        \"wandb\": {\n",
    "          \"project\": \"my-wandb-project\",\n",
    "          \"name\": \"finetome_try3\",\n",
    "          \"tags\": [\"project:tag\", \"lineage\"]\n",
    "        }\n",
    "      }],\n",
    ")\n",
    "print(response)\n",
    "job_id = response.id\n",
    "print(job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List fine-tuning jobs and events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "YdYbI3UpJXkr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-hlrL3gEeRxsO4xRXHVVp4OeW', created_at=1730071706, level='info', message='The job has successfully completed', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-1zL5V2XCPdS9ZCpypUGtF5PU', created_at=1730071700, level='info', message='New fine-tuned model created', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-mlF1wi5Dt26ZP4iH3C7SoKRF', created_at=1730071700, level='info', message='Checkpoint created at step 200', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-hA0Aq0KCh1zH0gab9ZhcJAW3', created_at=1730071700, level='info', message='Checkpoint created at step 100', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-0z73RSVNqQnGM1z6XhjHB06M', created_at=1730071673, level='info', message='Step 300/300: training loss=0.13, validation loss=0.40, full validation loss=0.77', object='fine_tuning.job.event', data={'step': 300, 'train_loss': 0.1308296024799347, 'valid_loss': 0.39652591681330457, 'total_steps': 300, 'full_valid_loss': 0.7684786162190117, 'train_mean_token_accuracy': 0.9540983438491821, 'valid_mean_token_accuracy': 0.8742138364779874, 'full_valid_mean_token_accuracy': 0.6649318136899665}, type='metrics'), FineTuningJobEvent(id='ftevent-0OR13lliUimmdtNBaZJjWWFU', created_at=1730071639, level='info', message='Step 299/300: training loss=0.37', object='fine_tuning.job.event', data={'step': 299, 'train_loss': 0.36926940083503723, 'total_steps': 300, 'train_mean_token_accuracy': 0.9020618796348572}, type='metrics'), FineTuningJobEvent(id='ftevent-raGqntp4HSGMFsGx8akhm6Iq', created_at=1730071638, level='info', message='Step 298/300: training loss=0.03', object='fine_tuning.job.event', data={'step': 298, 'train_loss': 0.030893893912434578, 'total_steps': 300, 'train_mean_token_accuracy': 0.9905063509941101}, type='metrics'), FineTuningJobEvent(id='ftevent-dkqE8ggbgINSAzFHK1U2MseN', created_at=1730071633, level='info', message='Step 297/300: training loss=0.09', object='fine_tuning.job.event', data={'step': 297, 'train_loss': 0.09432219713926315, 'total_steps': 300, 'train_mean_token_accuracy': 0.9793814420700073}, type='metrics'), FineTuningJobEvent(id='ftevent-AFSmIJLds3DyJbIoRKdlKpWQ', created_at=1730071633, level='info', message='Step 296/300: training loss=0.15', object='fine_tuning.job.event', data={'step': 296, 'train_loss': 0.14589877426624298, 'total_steps': 300, 'train_mean_token_accuracy': 0.9672130942344666}, type='metrics'), FineTuningJobEvent(id='ftevent-q0ro8SXIFqvWm7UnMzDvgfAl', created_at=1730071632, level='info', message='Step 295/300: training loss=0.13', object='fine_tuning.job.event', data={'step': 295, 'train_loss': 0.13313941657543182, 'total_steps': 300, 'train_mean_token_accuracy': 0.9573033452033997}, type='metrics'), FineTuningJobEvent(id='ftevent-hpyA3hS3ANWByFcWnFqdiEGd', created_at=1730071632, level='info', message='Step 294/300: training loss=0.14', object='fine_tuning.job.event', data={'step': 294, 'train_loss': 0.13997480273246765, 'total_steps': 300, 'train_mean_token_accuracy': 0.9581993818283081}, type='metrics'), FineTuningJobEvent(id='ftevent-E0lAFYAh0WzCVY2J1qAoQgo7', created_at=1730071631, level='info', message='Step 293/300: training loss=0.23', object='fine_tuning.job.event', data={'step': 293, 'train_loss': 0.22894838452339172, 'total_steps': 300, 'train_mean_token_accuracy': 0.9192824959754944}, type='metrics'), FineTuningJobEvent(id='ftevent-VozqPR6a92CIiwRyJHmYBhBL', created_at=1730071628, level='info', message='Step 292/300: training loss=0.08', object='fine_tuning.job.event', data={'step': 292, 'train_loss': 0.08118709176778793, 'total_steps': 300, 'train_mean_token_accuracy': 0.9723618030548096}, type='metrics'), FineTuningJobEvent(id='ftevent-NDsDT2SA04A7UFxVapet38Wp', created_at=1730071628, level='info', message='Step 291/300: training loss=0.58', object='fine_tuning.job.event', data={'step': 291, 'train_loss': 0.584693193435669, 'total_steps': 300, 'train_mean_token_accuracy': 0.850931704044342}, type='metrics'), FineTuningJobEvent(id='ftevent-0EiL84t1HbiQpqI6h7SYCnFC', created_at=1730071627, level='info', message='Step 290/300: training loss=0.19, validation loss=1.58', object='fine_tuning.job.event', data={'step': 290, 'train_loss': 0.1892988383769989, 'valid_loss': 1.5801018397013347, 'total_steps': 300, 'train_mean_token_accuracy': 0.9334638118743896, 'valid_mean_token_accuracy': 0.65}, type='metrics'), FineTuningJobEvent(id='ftevent-V4cyGGHfqUHQQsWlPJJ90njY', created_at=1730071627, level='info', message='Step 289/300: training loss=0.29', object='fine_tuning.job.event', data={'step': 289, 'train_loss': 0.29220327734947205, 'total_steps': 300, 'train_mean_token_accuracy': 0.909937858581543}, type='metrics'), FineTuningJobEvent(id='ftevent-jfwF1x7YzXyFXS3v1OiYwvFc', created_at=1730071623, level='info', message='Step 288/300: training loss=0.15', object='fine_tuning.job.event', data={'step': 288, 'train_loss': 0.1456119865179062, 'total_steps': 300, 'train_mean_token_accuracy': 0.9327731132507324}, type='metrics'), FineTuningJobEvent(id='ftevent-2rHM78lRQug9QXAcNMMYJl5A', created_at=1730071623, level='info', message='Step 287/300: training loss=0.27', object='fine_tuning.job.event', data={'step': 287, 'train_loss': 0.27042651176452637, 'total_steps': 300, 'train_mean_token_accuracy': 0.9136212468147278}, type='metrics'), FineTuningJobEvent(id='ftevent-640LE13fBwLnu6cyxyjyEFrc', created_at=1730071623, level='info', message='Step 286/300: training loss=0.46', object='fine_tuning.job.event', data={'step': 286, 'train_loss': 0.45897436141967773, 'total_steps': 300, 'train_mean_token_accuracy': 0.8301886916160583}, type='metrics'), FineTuningJobEvent(id='ftevent-wSzo8PSExGl5YNlYSkhNmkBK', created_at=1730071622, level='info', message='Step 285/300: training loss=0.31', object='fine_tuning.job.event', data={'step': 285, 'train_loss': 0.313036173582077, 'total_steps': 300, 'train_mean_token_accuracy': 0.8914728760719299}, type='metrics')], object='list', has_more=True)\n",
      "The job has successfully completed\n",
      "New fine-tuned model created\n",
      "Checkpoint created at step 200\n",
      "Checkpoint created at step 100\n",
      "Step 300/300: training loss=0.13, validation loss=0.40, full validation loss=0.77\n",
      "Step 299/300: training loss=0.37\n",
      "Step 298/300: training loss=0.03\n",
      "Step 297/300: training loss=0.09\n",
      "Step 296/300: training loss=0.15\n",
      "Step 295/300: training loss=0.13\n",
      "Step 294/300: training loss=0.14\n",
      "Step 293/300: training loss=0.23\n",
      "Step 292/300: training loss=0.08\n",
      "Step 291/300: training loss=0.58\n",
      "Step 290/300: training loss=0.19, validation loss=1.58\n",
      "Step 289/300: training loss=0.29\n",
      "Step 288/300: training loss=0.15\n",
      "Step 287/300: training loss=0.27\n",
      "Step 286/300: training loss=0.46\n",
      "Step 285/300: training loss=0.31\n"
     ]
    }
   ],
   "source": [
    "# client.fine_tuning.jobs.list(limit=5)\n",
    "# client.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "# Check job submission details of the fine-tuning job\n",
    "job_response = client.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id)\n",
    "print(job_response)\n",
    "\n",
    "# List event messages\n",
    "events = job_response.data\n",
    "# events\n",
    "for event in events:\n",
    "  print(event.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View Weights and Biases metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/christy/Documents/github_christy_copy_latest/Finetuning_demos/wandb/run-20241027_163659-ftjob-dNsMjoTKcaJFJndhzPBsQgwh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cbergman/OpenAI-Fine-Tune/runs/ftjob-dNsMjoTKcaJFJndhzPBsQgwh' target=\"_blank\">ftjob-dNsMjoTKcaJFJndhzPBsQgwh</a></strong> to <a href='https://wandb.ai/cbergman/OpenAI-Fine-Tune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cbergman/OpenAI-Fine-Tune' target=\"_blank\">https://wandb.ai/cbergman/OpenAI-Fine-Tune</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cbergman/OpenAI-Fine-Tune/runs/ftjob-dNsMjoTKcaJFJndhzPBsQgwh' target=\"_blank\">https://wandb.ai/cbergman/OpenAI-Fine-Tune/runs/ftjob-dNsMjoTKcaJFJndhzPBsQgwh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for the OpenAI fine-tuning job to finish training...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: To avoid blocking, you can call `WandbLogger.sync` with `wait_for_job_success=False` after OpenAI training completes.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Fine-tuning finished, logging metrics, model metadata, and run metadata to Weights & Biases\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging training/validation files...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▃▄▅▃▁▂▅▄▅▁▁▅▁▄▄▄▃▄▁▆▅▆▆▅▆▅▆▅▆▇▆▆▇▆▇▆▇▄█▇</td></tr><tr><td>train_loss</td><td>▆▅▅▄▇█▅▂▂▃▃▄▄▃▂▄▃▂▂▃▃▂▂▃▃▂▃▃▁▂▁▂▁▃▂▂▂▂▁▁</td></tr><tr><td>valid_loss</td><td>▇▂▃▂▃▆▃▅▄▆▃█▂▄▃▄▃▄▇▁▃▂▁▂▂▂▅▅▇▂</td></tr><tr><td>valid_mean_token_accuracy</td><td>▃▇▇▇▆▃▆▅▄▄▇▁▇▆▆▅▆▅▃█▆▇█▆█▇▅▅▃▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>fine_tuned_model</td><td>ft:gpt-4o-mini-2024-...</td></tr><tr><td>status</td><td>succeeded</td></tr><tr><td>train_accuracy</td><td>0.9541</td></tr><tr><td>train_loss</td><td>0.13083</td></tr><tr><td>valid_loss</td><td>0.39653</td></tr><tr><td>valid_mean_token_accuracy</td><td>0.87421</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ftjob-dNsMjoTKcaJFJndhzPBsQgwh</strong> at: <a href='https://wandb.ai/cbergman/OpenAI-Fine-Tune/runs/ftjob-dNsMjoTKcaJFJndhzPBsQgwh' target=\"_blank\">https://wandb.ai/cbergman/OpenAI-Fine-Tune/runs/ftjob-dNsMjoTKcaJFJndhzPBsQgwh</a><br/> View project at: <a href='https://wandb.ai/cbergman/OpenAI-Fine-Tune' target=\"_blank\">https://wandb.ai/cbergman/OpenAI-Fine-Tune</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241027_163659-ftjob-dNsMjoTKcaJFJndhzPBsQgwh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from wandb.integration.openai.fine_tuning import WandbLogger\n",
    "\n",
    "# one line command\n",
    "WandbLogger.sync()\n",
    "\n",
    "# passing optional parameters\n",
    "WandbLogger.sync(\n",
    "    fine_tune_job_id=None,\n",
    "    num_fine_tunes=None,\n",
    "    project=\"OpenAI-Fine-Tune\",\n",
    "    entity=None,\n",
    "    overwrite=False,\n",
    "    model_artifact_name=\"model-metadata\",\n",
    "    model_artifact_type=\"model\",\n",
    "    # **kwargs_wandb_init\n",
    ")\n",
    "\n",
    "# Web browser all fine-tuning jobs\n",
    "# https://wandb.ai/cbergman/OpenAI-Fine-Tune\n",
    "# Web browser single fine-tuning job\n",
    "# https://wandb.ai/cbergman/OpenAI-Fine-Tune/runs/ftjob-dPYoOEifQuaQ84BdJ5I8wWFK\n",
    "# https://wandb.ai/cbergman/OpenAI-Fine-Tune/runs/ftjob-dNsMjoTKcaJFJndhzPBsQgwh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get fine tuned model and checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import requests\n",
    "\n",
    "openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Define the API endpoint and headers\n",
    "url = f\"https://api.openai.com/v1/fine_tuning/jobs/{job_id}/checkpoints\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {openai_api_key}\"\n",
    "}\n",
    "\n",
    "# Make the API request\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    checkpoints = response.json()\n",
    "    # Get the checkpoints\n",
    "    for checkpoint in checkpoints['data']:\n",
    "        print(checkpoint)\n",
    "else:\n",
    "    print(f\"Failed to retrieve checkpoints: {response.status_code}\")\n",
    "    print(response.text)\n",
    "\n",
    "# Save the desired checkpoint ID\n",
    "chosen_checkpoint_step_number = checkpoints['data'][1]['step_number']\n",
    "print(f\"Using checkpoint: {chosen_checkpoint_step_number}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final fine-tuned model: ft:gpt-4o-mini-2024-07-18:christybergman-com:finetome-try3:AN6yBpe1\n"
     ]
    }
   ],
   "source": [
    "# Get the final fine-tuned model.\n",
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "fine_tune_model_id = response.fine_tuned_model\n",
    "print(f\"Final fine-tuned model: {fine_tune_model_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "coDp5s5JW9hk"
   },
   "source": [
    "### Generating using new model\n",
    "\n",
    "Use either the final fine-tuned model or any intermediate checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ft:gpt-4o-mini-2024-07-18:christybergman-com:finetome-try3:AN6yBKew:ckpt-step-200'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: how to get this from api, got below from console.\n",
    "inference_model_id = \"ft:gpt-4o-mini-2024-07-18:christybergman-com:finetome-try3:AN6yBKew:ckpt-step-200\"\n",
    "inference_model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fix this cell later.\n",
    "# Final fine-tuned model: ft:gpt-4o-mini-2024-07-18:christybergman-com:finetome-try3:AN6yBpe1\n",
    "\n",
    "# TODO replace checkpoint for the inference model id.\n",
    "# Assemble the full, checkpoint model_id.\n",
    "parts = str.split_parst(fine_tune_model_id, ':')\n",
    "print(parts)\n",
    "chosen_checkpoint_step_number = 200\n",
    "inference_model_id = parts[-1] + chosen_checkpoint_step_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read sample question from test data \n",
    "MESSAGE_NUM = 72  # 3, 80, 72\n",
    "sample_message = temp[MESSAGE_NUM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'Think before responding.'},\n",
       " {'role': 'user',\n",
       "  'content': 'Explain how the concept of signed area can be used to find the total area under the graph of $y=x^2$ from $x=-2$ to $x=2$, even though the function is not odd.'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'While $x^2$ is not an odd function, we can still use the concept of signed area to find the total area under its graph. We can split the integral into two parts: from $x=-2$ to $x=0$ and from $x=0$ to $x=2$. Since $x^2$ is negative below the x-axis from $x=-2$ to $x=0$, the integral over this interval will give a negative signed area. However, the integral from $x=0$ to $x=2$ will give a positive signed area. To find the total area, we can take the absolute value of the negative signed area and add it to the positive signed area, as follows:\\n\\n$$\\\\left|\\\\int_{-2}^0x^2dx\\\\right|+\\\\left|\\\\int_{0}^2x^2dx\\\\right|=\\\\frac{8}{3}+\\\\frac{8}{3}=\\\\frac{16}{3}.$$',\n",
       "  'weight': 1}]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_message['messages']['user']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'Think before responding.'},\n",
       " {'role': 'user',\n",
       "  'content': 'Explain how the concept of signed area can be used to find the total area under the graph of $y=x^2$ from $x=-2$ to $x=2$, even though the function is not odd.'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'While $x^2$ is not an odd function, we can still use the concept of signed area to find the total area under its graph. We can split the integral into two parts: from $x=-2$ to $x=0$ and from $x=0$ to $x=2$. Since $x^2$ is negative below the x-axis from $x=-2$ to $x=0$, the integral over this interval will give a negative signed area. However, the integral from $x=0$ to $x=2$ will give a positive signed area. To find the total area, we can take the absolute value of the negative signed area and add it to the positive signed area, as follows:\\n\\n$$\\\\left|\\\\int_{-2}^0x^2dx\\\\right|+\\\\left|\\\\int_{0}^2x^2dx\\\\right|=\\\\frac{8}{3}+\\\\frac{8}{3}=\\\\frac{16}{3}.$$',\n",
       "  'weight': 1}]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assemble the list of dictionaries called test_messages\n",
    "# Use convert_dicts() to re-format the message\n",
    "test_messages = convert_dicts([sample_message])\n",
    "test_messages[1]['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k0pHGcuVW7wY",
    "outputId": "cca69cdb-77a4-49f9-dc80-80fa5ec312f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The concept of signed area can help us find the total area above and below the x-axis, considering the areas with different signs. To find the area under the graph of \\(y=x^2\\) from \\(x=-2\\) to \\(x=2\\), we can divide the integral into two separate parts:\n",
      "\n",
      "1. From \\(x=-2\\) to \\(x=0\\) (area below the x-axis)\n",
      "2. From \\(x=0\\) to \\(x=2\\) (area above the x-axis)\n",
      "\n",
      "Since \\(x^2\\) is always positive over the closed interval \\([-2, 2]\\), there are no negative regions under its graph!\n",
      "\n",
      "However, instead of splitting the area into segments, we should directly compute:\n",
      "\n",
      "The required total area under \\(y = x^2\\) from \\(x=-2\\) to \\(x=2\\) can be calculated as follows:\n",
      "\n",
      "  \\[\n",
      "  \\text{Total Area} = \\int_{-2}^{2} x^2 \\,dx\n",
      "  \\]\n",
      "\n",
      "Performing the integration, we get:\n",
      "\n",
      "\\[\n",
      "= \\left[ \\frac{x^3}{3} \\right]_{-2}^{2} = \\frac{2^3}{3} - \\frac{(-2)^3}{3},  \\text{ where } x^3 \\text{ at } -2 \\text{ gives us positive value}\n",
      "\\]\n",
      "\n",
      "So:\n",
      " \\[\n",
      "2^3 - (-2)^3 = 8 - (-8) = 16\n",
      "\\]\n",
      "\n",
      "Thus:\n",
      " \\[\n",
      " = \\frac{16}{3}\n",
      "\\]\n",
      "And hence, we prefer the method of absolute integration over segmenting the calculations based on the negative regions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your fine-tuned model's inference answer.\n",
    "response = client.chat.completions.create(\n",
    "    model = inference_model_id,\n",
    "    messages = test_messages[1]['messages']\n",
    ")\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mNp0RGwyY9pU"
   },
   "outputs": [],
   "source": [
    "# Ground truth answer from test data.\n",
    "import pprint\n",
    "pprint.pprint(dataset[MESSAGE_NUM]['messages'][-1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Playground Fine Tuned Response\n",
    "\n",
    "# To find the region on a graph that satisfies the inequality #y-|x|>1#, we start by rewriting the \n",
    "# inequality as #y>1+|x|#. This means that we are looking for the values of #y# that are greater than #1+|x|#.\n",
    "# Next, we graph the line #y=1+|x|#. The graph of #y=|x|# is a V-shaped graph that opens upwards and has vertex \n",
    "# at the origin (0,0). Adding #1# to #y=|x|# simply shifts the graph of #y=|x|# upwards by #1#. \n",
    "# So the graph of #y=1+|x|# will be a V-shaped graph that opens upwards and has vertex at (0,1).\n",
    "# Therefore, the region that satisfies the inequality #y-|x|>1# is the region above the graph of #y=1+|x|#, \n",
    "# which is the shaded region above the line #y=1+|x|#.\n",
    "# In conclusion, the region on a graph that satisfies the inequality #y-|x|>1# is the region above the line #y=1+|x|#."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
